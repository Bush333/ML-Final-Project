{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzed2dBf6sUB"
      },
      "source": [
        "\n",
        "## Project: Building a Student Intervention System using Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WImEvh66sUK"
      },
      "source": [
        "## Exploring the Data\n",
        "Importing necessary libraries and reading our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV5ljXO76sUL",
        "outputId": "b3d62ab1-9cfc-47d4-b438-0067a5dd5c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student data read successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Read student data\n",
        "student_data = pd.read_csv(\"/content/Demographic.csv\")\n",
        "print(\"Student data read successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkUoJyGU6sUO"
      },
      "source": [
        "### Implementation: Data Exploration\n",
        "Investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students. In the code cell below, we will compute the following:\n",
        "- The total number of students, `n_students`.\n",
        "- The total number of features for each student, `n_features`.\n",
        "- The total number of students in maths course, `n_mat`.\n",
        "- The total number of students in portuguese course, `n_por`.\n",
        "- The number of those students who passed, `n_passed`.\n",
        "- The number of those students who failed, `n_failed`.\n",
        "- The graduation rate of the class, `grad_rate`, in percent (%).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt6FZRVF6sUP",
        "outputId": "d2e85069-1459-4000-cdd7-c0d34b66b2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of students: 1044\n",
            "Number of features: 19\n",
            "Number of students in maths course: 395\n",
            "Number of students in portuguese course: 649\n",
            "Number of students who passed: 814\n",
            "Number of students who failed: 230\n",
            "Graduation rate of the class: 77.97%\n",
            "\n",
            "F1 score for predicting all 'yes': 0.8762\n"
          ]
        }
      ],
      "source": [
        "# number of students\n",
        "n_students = len(student_data.index)\n",
        "\n",
        "# number of features, excluding the label column\n",
        "n_features = len(student_data.columns) - 1\n",
        "\n",
        "# passing students\n",
        "n_passed = len(student_data[student_data['passed'] == \"yes\"])\n",
        "\n",
        "# failing students.  \n",
        "n_failed = len(student_data[student_data['passed'] == \"no\"])\n",
        "\n",
        "# number of students in maths course\n",
        "#n_mat = len(student_data[student_data['course'] == \"mat\"])\n",
        "\n",
        "# number of students in portuguese course\n",
        "#n_por = len(student_data[student_data['course'] == \"por\"])\n",
        "\n",
        "# graduation rate\n",
        "grad_rate = n_passed / float(n_students) * 100.0\n",
        "\n",
        "print(\"Total number of students: {}\".format(n_students))\n",
        "print(\"Number of features: {}\".format(n_features))\n",
        "print(\"Number of students in maths course: {}\".format(n_mat))\n",
        "print(\"Number of students in portuguese course: {}\".format(n_por))\n",
        "print(\"Number of students who passed: {}\".format(n_passed))\n",
        "print(\"Number of students who failed: {}\".format(n_failed))\n",
        "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))\n",
        "\n",
        "print(\"\\nF1 score for predicting all 'yes': {:.4f}\".format(\n",
        "    f1_score(y_true = ['yes']*n_passed + ['no']*n_failed, y_pred = ['yes']*n_students, pos_label='yes', average='binary')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slmz1dyT6sUR"
      },
      "source": [
        "## Preparing the Data\n",
        "Preparation of the data for modeling, training and testing.\n",
        "\n",
        "### Identify feature and target columns\n",
        "Separating the student data into feature and target columns to see if any features are non-numeric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kouMRVeV6sUS",
        "outputId": "5b5a1e72-8ac3-4c4c-fb16-644d54db484d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature columns:\n",
            "['sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'guardian', 'traveltime', 'activities', 'nursery', 'internet', 'romantic', 'famrel', 'freetime', 'Dalc', 'Walc']\n",
            "\n",
            "Target column:+ passed\n",
            "\n",
            "Feature values:\n",
            "  sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob guardian  \\\n",
            "0   F   18       U     GT3       A     4     4  at_home   teacher   mother   \n",
            "1   F   17       U     GT3       T     1     1  at_home     other   father   \n",
            "2   F   15       U     LE3       T     1     1  at_home     other   mother   \n",
            "3   F   15       U     GT3       T     4     2   health  services   mother   \n",
            "4   F   16       U     GT3       T     3     3    other     other   father   \n",
            "\n",
            "   traveltime activities nursery internet romantic  famrel  freetime  Dalc  \\\n",
            "0           2         no     yes       no       no       4         3     1   \n",
            "1           1         no      no      yes       no       5         3     1   \n",
            "2           1         no     yes      yes       no       4         3     2   \n",
            "3           1        yes     yes      yes      yes       3         2     1   \n",
            "4           1         no     yes       no       no       4         3     1   \n",
            "\n",
            "   Walc  \n",
            "0     1  \n",
            "1     1  \n",
            "2     3  \n",
            "3     1  \n",
            "4     2  \n"
          ]
        }
      ],
      "source": [
        "# Extracting feature columns\n",
        "feature_cols = list(student_data.columns[:-1])\n",
        "\n",
        "# Extracting target column 'passed'\n",
        "target_col = student_data.columns[-1] \n",
        "\n",
        "# list of columns\n",
        "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
        "print(\"\\nTarget column:+ {}\".format(target_col))\n",
        "\n",
        "# Separating the data into feature data and target data (X_all and y_all, respectively)\n",
        "X_all = student_data[feature_cols]\n",
        "y_all = student_data[target_col]\n",
        "\n",
        "print(\"\\nFeature values:\")\n",
        "print(X_all.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Wdn5qV6sUT"
      },
      "source": [
        "### Preprocess Feature Columns\n",
        "Preprocessing of dataset to take care of non-numeric columns and also columns with have more than two value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLcEWAxm6sUT",
        "outputId": "64e14ac2-d401-4d9e-eb62-efade1465c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed feature columns (33 total features):\n",
            "['sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'activities', 'nursery', 'internet', 'romantic', 'famrel', 'freetime', 'Dalc', 'Walc']\n"
          ]
        }
      ],
      "source": [
        "def preprocess_features(X):\n",
        "    ''' Preprocessesing the student data and converting non-numeric binary variables into\n",
        "        binary (0/1) variables. Converting categorical variables into dummy variables. '''\n",
        "    \n",
        "    # Initialize new output DataFrame\n",
        "    output = pd.DataFrame(index = X.index)\n",
        "\n",
        "    # Investigate each feature column for the data\n",
        "    for col, col_data in X.iteritems():\n",
        "        \n",
        "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
        "        if col_data.dtype == object:\n",
        "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
        "\n",
        "        # If data type is categorical, convert to dummy variables\n",
        "        if col_data.dtype == object:\n",
        "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
        "        \n",
        "        # Collect the revised columns\n",
        "        output = output.join(col_data)\n",
        "    \n",
        "    return output\n",
        "\n",
        "X_all = preprocess_features(X_all)\n",
        "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2bepHIx6sUU"
      },
      "source": [
        "### Implementation: Training and Testing Data Split\n",
        "Spliting the dataset into training and test sets.\n",
        "Using approx 800 training points and 200 testing points (80:20 ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2OKTS7v6sUV",
        "outputId": "98537d63-aaea-48a8-b353-3c551720a907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 830 samples.\n",
            "Testing set has 214 samples.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Setting the number of training points\n",
        "num_train = 830\n",
        "\n",
        "# Setting the number of testing points\n",
        "num_test = X_all.shape[0] - num_train\n",
        "\n",
        "# Shuffling and splitting the dataset into the number of training and testing points above\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all,train_size=num_train,test_size=num_test,random_state=0,stratify=y_all)\n",
        "\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1A00vjW6sUV"
      },
      "source": [
        "## Training and Evaluating Models\n",
        "Selecting and evaluating three supervised learning models\n",
        "\n",
        "- Gaussian Naive Bayes (GaussianNB)\n",
        "- Decision Trees\n",
        "- Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "7FB5-Q0O6sUX"
      },
      "outputs": [],
      "source": [
        "def train_classifier(clf, X_train, y_train):\n",
        "    ''' Fits a classifier to the training data. '''\n",
        "    \n",
        "    # Start the clock, train the classifier, then stop the clock\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    tdiff = end - start\n",
        "    \n",
        "    print(\"Trained model in {:.4f} seconds\".format(tdiff))\n",
        "    return tdiff\n",
        "\n",
        "    \n",
        "def predict_labels(clf, features, target):\n",
        "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
        "    \n",
        "    # Start the clock, make predictions, then stop the clock\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    end = time()\n",
        "    tdiff = end - start\n",
        "\n",
        "    print(\"Made predictions in {:.4f} seconds.\".format(tdiff))\n",
        "    return f1_score(target.values, y_pred, pos_label='yes'),tdiff\n",
        "\n",
        "\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "    ''' Train and predict using a classifer based on F1 score. '''\n",
        "    \n",
        "    # Indicate the classifier and the training set size\n",
        "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
        "    \n",
        "    # Train the classifier\n",
        "    train_time = train_classifier(clf, X_train, y_train)\n",
        "    \n",
        "    # Print the results of prediction for both training and testing, and return them\n",
        "    f1_train, prediction_time_train = predict_labels(clf, X_train, y_train)\n",
        "    print(\"F1 score for training set: {:.4f}.\".format(f1_train))\n",
        "    f1_test, prediction_time_test = predict_labels(clf, X_test, y_test)\n",
        "    print(\"F1 score for test set: {:.4f}.\".format(f1_test))\n",
        "    return train_time,prediction_time_test,f1_train,f1_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY5byAOb6sUZ",
        "outputId": "317b51aa-33f4-4065-cac8-a1bd75b4e1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for predicting all \"yes\" on test set: 0.8766\n",
            "Training a GaussianNB using a training set size of 100. . .\n",
            "Trained model in 0.0045 seconds\n",
            "Made predictions in 0.0022 seconds.\n",
            "F1 score for training set: 0.2651.\n",
            "Made predictions in 0.0045 seconds.\n",
            "F1 score for test set: 0.1702.\n",
            "Training a GaussianNB using a training set size of 200. . .\n",
            "Trained model in 0.0042 seconds\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for training set: 0.2759.\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for test set: 0.2323.\n",
            "Training a GaussianNB using a training set size of 300. . .\n",
            "Trained model in 0.0038 seconds\n",
            "Made predictions in 0.0033 seconds.\n",
            "F1 score for training set: 0.1092.\n",
            "Made predictions in 0.0029 seconds.\n",
            "F1 score for test set: 0.0571.\n",
            "Training a GaussianNB using a training set size of 400. . .\n",
            "Trained model in 0.0047 seconds\n",
            "Made predictions in 0.0028 seconds.\n",
            "F1 score for training set: 0.7398.\n",
            "Made predictions in 0.0032 seconds.\n",
            "F1 score for test set: 0.6950.\n",
            "Training a GaussianNB using a training set size of 500. . .\n",
            "Trained model in 0.0048 seconds\n",
            "Made predictions in 0.0027 seconds.\n",
            "F1 score for training set: 0.8090.\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for test set: 0.7653.\n",
            "Training a GaussianNB using a training set size of 600. . .\n",
            "Trained model in 0.0045 seconds\n",
            "Made predictions in 0.0027 seconds.\n",
            "F1 score for training set: 0.8132.\n",
            "Made predictions in 0.0035 seconds.\n",
            "F1 score for test set: 0.7888.\n",
            "Training a GaussianNB using a training set size of 700. . .\n",
            "Trained model in 0.0053 seconds\n",
            "Made predictions in 0.0028 seconds.\n",
            "F1 score for training set: 0.8221.\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for test set: 0.7764.\n",
            "Training a GaussianNB using a training set size of 800. . .\n",
            "Trained model in 0.0054 seconds\n",
            "Made predictions in 0.0078 seconds.\n",
            "F1 score for training set: 0.8010.\n",
            "Made predictions in 0.0029 seconds.\n",
            "F1 score for test set: 0.7643.\n",
            "Training a DecisionTreeClassifier using a training set size of 100. . .\n",
            "Trained model in 0.0041 seconds\n",
            "Made predictions in 0.0023 seconds.\n",
            "F1 score for training set: 1.0000.\n",
            "Made predictions in 0.0030 seconds.\n",
            "F1 score for test set: 0.6842.\n",
            "Training a DecisionTreeClassifier using a training set size of 200. . .\n",
            "Trained model in 0.0048 seconds\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for training set: 0.9863.\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for test set: 0.7610.\n",
            "Training a DecisionTreeClassifier using a training set size of 300. . .\n",
            "Trained model in 0.0087 seconds\n",
            "Made predictions in 0.0029 seconds.\n",
            "F1 score for training set: 0.9819.\n",
            "Made predictions in 0.0034 seconds.\n",
            "F1 score for test set: 0.7842.\n",
            "Training a DecisionTreeClassifier using a training set size of 400. . .\n",
            "Trained model in 0.0077 seconds\n",
            "Made predictions in 0.0024 seconds.\n",
            "F1 score for training set: 0.9850.\n",
            "Made predictions in 0.0020 seconds.\n",
            "F1 score for test set: 0.7213.\n",
            "Training a DecisionTreeClassifier using a training set size of 500. . .\n",
            "Trained model in 0.0121 seconds\n",
            "Made predictions in 0.0027 seconds.\n",
            "F1 score for training set: 0.9830.\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for test set: 0.7378.\n",
            "Training a DecisionTreeClassifier using a training set size of 600. . .\n",
            "Trained model in 0.0067 seconds\n",
            "Made predictions in 0.0030 seconds.\n",
            "F1 score for training set: 0.9836.\n",
            "Made predictions in 0.0025 seconds.\n",
            "F1 score for test set: 0.7904.\n",
            "Training a DecisionTreeClassifier using a training set size of 700. . .\n",
            "Trained model in 0.0072 seconds\n",
            "Made predictions in 0.0026 seconds.\n",
            "F1 score for training set: 0.9814.\n",
            "Made predictions in 0.0031 seconds.\n",
            "F1 score for test set: 0.7859.\n",
            "Training a DecisionTreeClassifier using a training set size of 800. . .\n",
            "Trained model in 0.0071 seconds\n",
            "Made predictions in 0.0027 seconds.\n",
            "F1 score for training set: 0.9781.\n",
            "Made predictions in 0.0022 seconds.\n",
            "F1 score for test set: 0.7842.\n",
            "Training a SVC using a training set size of 100. . .\n",
            "Trained model in 0.0045 seconds\n",
            "Made predictions in 0.0023 seconds.\n",
            "F1 score for training set: 0.8372.\n",
            "Made predictions in 0.0029 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 200. . .\n",
            "Trained model in 0.0050 seconds\n",
            "Made predictions in 0.0039 seconds.\n",
            "F1 score for training set: 0.8506.\n",
            "Made predictions in 0.0058 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 300. . .\n",
            "Trained model in 0.0092 seconds\n",
            "Made predictions in 0.0061 seconds.\n",
            "F1 score for training set: 0.8550.\n",
            "Made predictions in 0.0085 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 400. . .\n",
            "Trained model in 0.0119 seconds\n",
            "Made predictions in 0.0117 seconds.\n",
            "F1 score for training set: 0.8604.\n",
            "Made predictions in 0.0068 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 500. . .\n",
            "Trained model in 0.0200 seconds\n",
            "Made predictions in 0.0136 seconds.\n",
            "F1 score for training set: 0.8713.\n",
            "Made predictions in 0.0071 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 600. . .\n",
            "Trained model in 0.0254 seconds\n",
            "Made predictions in 0.0281 seconds.\n",
            "F1 score for training set: 0.8679.\n",
            "Made predictions in 0.0133 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 700. . .\n",
            "Trained model in 0.0304 seconds\n",
            "Made predictions in 0.0271 seconds.\n",
            "F1 score for training set: 0.8746.\n",
            "Made predictions in 0.0091 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "Training a SVC using a training set size of 800. . .\n",
            "Trained model in 0.0371 seconds\n",
            "Made predictions in 0.0298 seconds.\n",
            "F1 score for training set: 0.8756.\n",
            "Made predictions in 0.0131 seconds.\n",
            "F1 score for test set: 0.8766.\n",
            "----- MARKDOWN -----\n",
            "** Classifer 1 - GaussianNB**\n",
            "\n",
            " TST: Training Set Size\n",
            " TT : Training Time \n",
            " PT: Prediction Time(test) \n",
            " F1_train : F1 Score (train) \n",
            " F1_test : F1 Score (test)\n",
            "\n",
            "| TST |   TT   |   PT   | F1_train | F1_test |\n",
            "| 100 | 0.0045 | 0.0045 | 0.2651 | 0.1702 |\n",
            "| 200 | 0.0042 | 0.0026 | 0.2759 | 0.2323 |\n",
            "| 300 | 0.0038 | 0.0029 | 0.1092 | 0.0571 |\n",
            "| 400 | 0.0047 | 0.0032 | 0.7398 | 0.6950 |\n",
            "| 500 | 0.0048 | 0.0026 | 0.8090 | 0.7653 |\n",
            "| 600 | 0.0045 | 0.0035 | 0.8132 | 0.7888 |\n",
            "| 700 | 0.0053 | 0.0026 | 0.8221 | 0.7764 |\n",
            "| 800 | 0.0054 | 0.0029 | 0.8010 | 0.7643 |\n",
            "\n",
            "\n",
            "** Classifer 2 - Decision Tree**\n",
            "\n",
            " TST: Training Set Size\n",
            " TT : Training Time \n",
            " PT: Prediction Time(test) \n",
            " F1_train : F1 Score (train) \n",
            " F1_test : F1 Score (test)\n",
            "\n",
            "| TST |   TT   |   PT   | F1_train | F1_test |\n",
            "| 100 | 0.0041 | 0.0030 | 1.0000 | 0.6842 |\n",
            "| 200 | 0.0048 | 0.0026 | 0.9863 | 0.7610 |\n",
            "| 300 | 0.0087 | 0.0034 | 0.9819 | 0.7842 |\n",
            "| 400 | 0.0077 | 0.0020 | 0.9850 | 0.7213 |\n",
            "| 500 | 0.0121 | 0.0026 | 0.9830 | 0.7378 |\n",
            "| 600 | 0.0067 | 0.0025 | 0.9836 | 0.7904 |\n",
            "| 700 | 0.0072 | 0.0031 | 0.9814 | 0.7859 |\n",
            "| 800 | 0.0071 | 0.0022 | 0.9781 | 0.7842 |\n",
            "\n",
            "\n",
            "** Classifer 3 - Support Vector Machines**\n",
            "\n",
            " TST: Training Set Size\n",
            " TT : Training Time \n",
            " PT: Prediction Time(test) \n",
            " F1_train : F1 Score (train) \n",
            " F1_test : F1 Score (test)\n",
            "\n",
            "| TST |   TT   |   PT   | F1_train | F1_test |\n",
            "| 100 | 0.0045 | 0.0029 | 0.8372 | 0.8766 |\n",
            "| 200 | 0.0050 | 0.0058 | 0.8506 | 0.8766 |\n",
            "| 300 | 0.0092 | 0.0085 | 0.8550 | 0.8766 |\n",
            "| 400 | 0.0119 | 0.0068 | 0.8604 | 0.8766 |\n",
            "| 500 | 0.0200 | 0.0071 | 0.8713 | 0.8766 |\n",
            "| 600 | 0.0254 | 0.0133 | 0.8679 | 0.8766 |\n",
            "| 700 | 0.0304 | 0.0091 | 0.8746 | 0.8766 |\n",
            "| 800 | 0.0371 | 0.0131 | 0.8756 | 0.8766 |\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the three supervised learning models from sklearn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import resample\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.ensemble import BaggingClassifier as BC\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Get a benchmark score\n",
        "print(\"F1 score for predicting all \\\"yes\\\" on test set: {:.4f}\".format(\n",
        "    f1_score(y_test, ['yes']*len(y_test), pos_label='yes', average='binary')))\n",
        "\n",
        "# Initialize and setup the three models\n",
        "classifiers = [\n",
        "    { 'name' : \"GaussianNB\", 'clf' : GaussianNB() },\n",
        "    { 'name' : \"Decision Tree\", 'clf' : DecisionTreeClassifier(criterion=\"entropy\",random_state=0) },\n",
        "    { 'name' : \"Support Vector Machines\", 'clf' : SVC(random_state=0) },\n",
        "]\n",
        "\n",
        "# Resample and store our training sets in specific sizes, in training_sets for 100,200 and 300\n",
        "training_sets = []\n",
        "for train_size in range(100,830,100):\n",
        "    X_res, y_res = resample(X_train,y_train,n_samples=train_size,random_state=0)\n",
        "    training_sets.append ({ 'size' : train_size, 'X_train' : X_res, 'y_train' : y_res })\n",
        "\n",
        "# Loop through each classifer,  and each training set size and test our model\n",
        "for clfData in classifiers:\n",
        "    clfData['results'] = []\n",
        "    for tset in training_sets:\n",
        "        train_time,prediction_time_test,f1_train,f1_test = \\\n",
        "        train_predict(clfData['clf'], tset['X_train'], tset['y_train'], X_test, y_test)\n",
        "        \n",
        "        # Store our results\n",
        "        clfData['results'].append({'train_time' : train_time, 'prediction_time_test' : prediction_time_test,\n",
        "                                   'f1_train' : f1_train, 'f1_test' : f1_test, 'size' : tset['size']})\n",
        "        \n",
        "# Generate markdown\n",
        "print('----- MARKDOWN -----')\n",
        "i = 0\n",
        "for clfData in classifiers:\n",
        "    i += 1\n",
        "    print('** Classifer {} - {}**\\n'.format(i,clfData['name']))\n",
        "    print(' TST: Training Set Size\\n'\n",
        "          ' TT : Training Time \\n'\n",
        "          ' PT: Prediction Time(test) \\n'\n",
        "          ' F1_train : F1 Score (train) \\n'\n",
        "          ' F1_test : F1 Score (test)\\n')\n",
        "    print(\"| TST |   TT   |   PT   | F1_train | F1_test |\")\n",
        "    for result in clfData['results']:\n",
        "        print('| {} | {:.4f} | {:.4f} | {:.4f} | {:.4f} |'.format(result['size'], result['train_time'], \n",
        "                                                       result['prediction_time_test'],result['f1_train'],result['f1_test']))\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEzyqyET6sUZ"
      },
      "source": [
        "### Tabular Results\n",
        "Edit the cell below to see how a table can be designed in [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). You can record your results from above in the tables provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKvKQiw_6sUZ"
      },
      "source": [
        "** Classifer 1 - GaussianNB**\n",
        "\n",
        "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
        "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
        "| 100 | 0.0040 | 0.0032 | 0.5102 | 0.4344 |\n",
        "| 200 | 0.0047 | 0.0029 | 0.4670 | 0.3585 |\n",
        "| 300 | 0.0088 | 0.0037 | 0.4291 | 0.3398 |\n",
        "| 400 | 0.0045 | 0.0025 | 0.8514 | 0.7975 |\n",
        "| 500 | 0.0097 | 0.0025 | 0.8763 | 0.8135 |\n",
        "| 600 | 0.0049 | 0.0026 | 0.8780 | 0.8348 |\n",
        "| 700 | 0.0058 | 0.0025 | 0.8804 | 0.8348 |\n",
        "| 800 | 0.0050 | 0.0027 | 0.8811 | 0.8303 |\n",
        "\n",
        "** Classifer 2 - Decision Tree**\n",
        "\n",
        "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
        "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
        "| 100 | 0.0043 | 0.0024 | 1.0000 | 0.8012 |\n",
        "| 200 | 0.0044 | 0.0023 | 1.0000 | 0.8131 |\n",
        "| 300 | 0.0056 | 0.0030 | 1.0000 | 0.8354 |\n",
        "| 400 | 0.0062 | 0.0028 | 1.0000 | 0.8520 |\n",
        "| 500 | 0.0062 | 0.0041 | 1.0000 | 0.7890 |\n",
        "| 600 | 0.0098 | 0.0034 | 1.0000 | 0.8343 |\n",
        "| 700 | 0.0111 | 0.0019 | 1.0000 | 0.8378 |\n",
        "| 800 | 0.0095 | 0.0018 | 1.0000 | 0.8393 |\n",
        "\n",
        "** Classifer 3 - Support Vector Machines**\n",
        "\n",
        "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
        "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
        "| 100 | 0.0033 | 0.0036 | 0.8372 | 0.8766 |\n",
        "| 200 | 0.0058 | 0.0058 | 0.8506 | 0.8766 |\n",
        "| 300 | 0.0085 | 0.0059 | 0.8550 | 0.8766 |\n",
        "| 400 | 0.0158 | 0.0070 | 0.8604 | 0.8766 |\n",
        "| 500 | 0.0180 | 0.0082 | 0.8713 | 0.8766 |\n",
        "| 600 | 0.0271 | 0.0097 | 0.8679 | 0.8766 |\n",
        "| 700 | 0.0265 | 0.0115 | 0.8767 | 0.8766 |\n",
        "| 800 | 0.0318 | 0.0129 | 0.8787 | 0.8766 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bSScn_v6sUb"
      },
      "source": [
        "\n",
        "Support Vector Machines (SVM) basically work by trying to identify the reasons why a student switches from a 'fail' to a 'pass'.  In other words, it isn't very concerned with people who are comfortably passing or failing, but rather what the differences are between students who have only *just* passed, or only *just* failed.   It will try to establish this *boundary* between marginal students as clearly as possible, thus enabling it to figure out what the most important factors are in getting students to pass.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRokuyOt6sUb"
      },
      "source": [
        "### Implementation: Model Tuning\n",
        "Using grid search (`GridSearchCV`) with at least one important parameter tuned with at least 3 different values. You will need to use the entire training set for this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awPG_qgL6sUb"
      },
      "outputs": [],
      "source": [
        "# Import 'GridSearchCV' and 'make_scorer'\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "from IPython.display import display\n",
        "def f1_wrap(y_true, y_predict):\n",
        "    return f1_score(y_true, y_predict, pos_label='yes')\n",
        "\n",
        "# Create the parameters list you wish to tune.  Warning, takes ~15 seconds to compute!\n",
        "parameters = {'C':range(1,6),'kernel':['linear','poly','rbf','sigmoid'],'degree':range(1,6)}\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = SVC(random_state=0)\n",
        "\n",
        "# Make an f1 scoring function using 'make_scorer' \n",
        "f1_scorer = make_scorer(f1_wrap)\n",
        "\n",
        "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "grid_obj = GridSearchCV(clf, parameters, scoring=f1_scorer)\n",
        "# Fit the grid search object to the training data and find the optimal parameters\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "# Get the estimator\n",
        "clf = grid_obj.best_estimator_\n",
        "\n",
        "# Print the final parameters\n",
        "df = pd.DataFrame(grid_obj.cv_results_).sort_values('mean_test_score').tail()\n",
        "display(df)\n",
        "print(\"Parameters for the optimal model: {}\".format(clf.get_params()))\n",
        "# Report the final F1 score for training and testing after parameter tuning\n",
        "print(\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)[0]))\n",
        "print(\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDMzz3TW6sUc"
      },
      "source": [
        "\n",
        "- Final F<sub>1</sub> score for training: 0.8761\n",
        "- Final F<sub>1</sub> score for testing: 0.8766\n",
        "- Previous F<sub>1</sub> score for training: 0.8756\n",
        "- Previous F<sub>1</sub> score for testing: 0.8766\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0s3jJhj6sUc"
      },
      "source": [
        "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
        "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "student_intervention (1).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}